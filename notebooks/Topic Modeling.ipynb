{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data.fetch_data import get_submission_docs_for_subreddit\n",
    "\n",
    "%aimport data.fetch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize, MWETokenizer # multi-word expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of comments by most prolific user: 0.02629016553067186\n"
     ]
    }
   ],
   "source": [
    "data = get_submission_docs_for_subreddit('democrats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove punctuation, remove words containing numbers, remove links.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('\\w*http\\w*|\\w*www\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data.copy()\n",
    "data_clean.text = data.text.map(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_stop_words = [\n",
    "    'like', 'dont', 'im', 'say', 'did', 'said', 'thats', 'don', 'hes', 'does', 'thing', 'gt', 'sure', 'doesnt',\n",
    "    'saying', 'youre', 'isnt', 'doing', 'got', 'didnt', 'yeah', 'just', 'yes',\n",
    "    'right', 'think', 'going', 'want', 'know', 'good',\n",
    "    'need', 'time', 'point', 'make', 'way', 'really',\n",
    "    'id', 'ar', 's', 't', 've', 'm', 'shes',\n",
    "]\n",
    "multi_words = [\n",
    "    ('health','insurance'),\n",
    "    ('fox', 'news'),\n",
    "    ('bernie', 'sanders'),\n",
    "    ('hillary', 'clinton'),\n",
    "    ('barack', 'obama'),\n",
    "    ('donald', 'trump'),\n",
    "    ('joe', 'biden'),\n",
    "    ('joseph', 'biden'),\n",
    "    ('mass', 'shooting'),\n",
    "    ('mass', 'shootings'),\n",
    "    ('assault', 'weapon'),\n",
    "    ('assault', 'weapons'),\n",
    "    ('assault', 'weapons', 'ban'),\n",
    "    ('sergeant', 'at', 'arms'),\n",
    "    ('stop', 'and', 'frisk'),\n",
    "    ('medicare', 'for', 'all'),\n",
    "    ('public', 'option'),\n",
    "    ('beat', 'trump')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwe_tokenizer = MWETokenizer(multi_words)\n",
    "\n",
    "stop_words = ENGLISH_STOP_WORDS.union(additional_stop_words)\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    stop_words=stop_words,\n",
    "    tokenizer=lambda x: mwe_tokenizer.tokenize(word_tokenize(x)),\n",
    "    max_df=0.75\n",
    ")\n",
    "data_cv = cv.fit_transform(data_clean.text)\n",
    "data_dtm_raw = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm_raw.index = data_clean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zum</th>\n",
       "      <th>£</th>\n",
       "      <th>­</th>\n",
       "      <th>¯ツ¯</th>\n",
       "      <th>¿</th>\n",
       "      <th>¿philanthropist</th>\n",
       "      <th>élection</th>\n",
       "      <th>͜ʖ</th>\n",
       "      <th>͡ʘ</th>\n",
       "      <th>американец</th>\n",
       "      <th>говорить</th>\n",
       "      <th>как</th>\n",
       "      <th>​theres</th>\n",
       "      <th>–</th>\n",
       "      <th>–jackson–kingday</th>\n",
       "      <th>–nebraskaact</th>\n",
       "      <th>—</th>\n",
       "      <th>—and</th>\n",
       "      <th>—donald</th>\n",
       "      <th>—gt</th>\n",
       "      <th>—the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zum  £  ­  ¯ツ¯  ¿  ¿philanthropist  élection  ͜ʖ  ͡ʘ  американец  говорить  \\\n",
       "0    0  0  0    0  0                0         0   0   0           0         0   \n",
       "1    0  0  0    0  0                1         0   0   0           0         0   \n",
       "3    0  0  0    0  0                0         0   0   0           0         0   \n",
       "4    0  0  0    0  0                0         0   0   0           0         0   \n",
       "6    0  0  0    0  0                0         0   0   0           0         0   \n",
       "\n",
       "   как  ​theres  –  –jackson–kingday  –nebraskaact  —  —and  —donald  —gt  \\\n",
       "0    0        0  0                 0             0  0     0        0    0   \n",
       "1    0        0  0                 0             0  0     0        0    0   \n",
       "3    0        0  0                 0             0  0     0        0    0   \n",
       "4    0        0  0                 0             0  0     0        0    0   \n",
       "6    0        0  0                 0             0  0     0        0    0   \n",
       "\n",
       "   —the  \n",
       "0     0  \n",
       "1     0  \n",
       "3     0  \n",
       "4     0  \n",
       "6     0  "
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dtm_raw.iloc[:5, -171:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove russian words, emojis, other weird stuff\n",
    "data_dtm = data_dtm_raw.iloc[:, :-170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could do stemming, lemmatization, parts of speech, compound term extraction / named entity extraction, IF-IDF\n",
    "# lots of emoji's' now with nltk tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_counts = pd.DataFrame(np.sum(data_dtm.transpose(), axis=1), columns=['word_count'], index=data_dtm.transpose().index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_counts.word_count.sort_values(ascending=False).iloc[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "word_counts.sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# lots of omitted spaces\n",
    "# fair number of spelling errors\n",
    "    # problem is, TextBlob can't find omitted spaces and corrects things like \"pelosi\" to \"pelvis\"\n",
    "    # omit for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio:  [0.08639577 0.04972536 0.03549208 0.03375841 0.02473922]\n",
      "\n",
      "Topic: ' Election '\n",
      "vote, bernie, biden, president, party, republicans, election, democrats, republican, candidate, years, warren, better, actually, senate, support, sanders, things, house, money, country, lot, democratic, voting, power, bad, shit, voters, person, win\n",
      "\n",
      "Topic: ' Impeachment '\n",
      "power, congress, house, contempt, detain, senate, court, person, arrest, supreme, impeachment, hold, law, republicans, sergeant_at_arms, vote, authority, president, case, inherent, majority, impeached, democrats, dc, constitution, jail, trial, persons, session, pelosi\n",
      "\n",
      "Topic: ' Unclear - policy mix '\n",
      "gun, tax, pay, cost, taxes, billion, government, healthcare, care, money, costs, health, spending, guns, insurance, percent, private, public, republicans, hospitals, million, use, ban, services, year, impeachment, medical, paid, increase, income\n",
      "\n",
      "Topic: ' Unclear - maybe Health Care '\n",
      "congress, healthcare, billion, bernie, contempt, detain, cost, tax, pay, power, biden, taxes, warren, costs, health, person, spending, insurance, percent, arrest, money, court, hospitals, private, care, sanders, house, medical, million, services\n",
      "\n",
      "Topic: ' Gun Violence/Assault Weapons ban '\n",
      "vote, gun, guns, voting, ban, laws, weapons, rights, rifles, used, away, voter, firearms, person, amendment, states, party, state, detain, common, mass_shootings, firearm, number, contempt, owners, beto, deaths, arms, banning, awb\n"
     ]
    }
   ],
   "source": [
    "lsa = TruncatedSVD(5)\n",
    "doc_topic = lsa.fit_transform(data_dtm)\n",
    "print('Explained Variance Ratio: ', lsa.explained_variance_ratio_)\n",
    "display_topics(\n",
    "    lsa,\n",
    "    cv.get_feature_names()[:-171],\n",
    "    30,\n",
    "    topic_names=['Election', 'Impeachment', 'Unclear - tax policy', 'Unclear - maybe Health Care', 'Gun Violence/Assault Weapons ban']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt = pd.DataFrame(doc_topic.round(5),\n",
    "             index = example,\n",
    "             columns = [\"component_1\",\"component_2\" ])\n",
    "Vt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(5)\n",
    "doc_topic = lsa.fit_transform(data_dtm)\n",
    "print('Explained Variance Ratio: ', lsa.explained_variance_ratio_)\n",
    "display_topics(\n",
    "    lsa,\n",
    "    cv.get_feature_names()[:-171],\n",
    "    30,\n",
    "    topic_names=['Election', 'Impeachment', 'Unclear - tax policy', 'Unclear - maybe Health Care', 'Gun Violence/Assault Weapons ban']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
