{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "sys.path.append('../../src')\n",
    "\n",
    "from data.fetch_data import get_submission_docs_for_subreddit\n",
    "from data.clean_data import process_text\n",
    "\n",
    "%aimport data.fetch_data\n",
    "%aimport data.clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import word_tokenize, MWETokenizer # multi-word expression\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.tag import pos_tag\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of comments by most prolific user: 0.02629016553067186\n"
     ]
    }
   ],
   "source": [
    "data_raw = get_submission_docs_for_subreddit('democrats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data_raw.copy()\n",
    "data_clean.text = data_clean.text.map(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/interim/rDemocrats_data_clean.pickle', 'wb') as write_file:\n",
    "    pickle.dump(data_clean, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_stop_words = [\n",
    "    'like', 'dont', 'im', 'say', 'did', 'said', 'thats', 'don', 'hes', 'does', 'thing', 'gt', 'sure', 'doesnt',\n",
    "    'saying', 'youre', 'isnt', 'doing', 'got', 'didnt', 'yeah', 'just', 'yes',\n",
    "    'right', 'think', 'going', 'want', 'know', 'good',\n",
    "    'need', 'time', 'point', 'make', 'way', 'really',\n",
    "    'id', 'ar', 's', 't', 've', 'm', 'shes', \n",
    "    'c', 'd', 'v', 'actually', 'look', 'maybe', 'though', 'bad', 'came', 'mods', 'things', 'lot', 'let', 'lol', 'tell', 'pretty', 'literally'\n",
    "    'theyre', 'people',\n",
    "    '‘', '’', '“'\n",
    "]\n",
    "multi_words = [\n",
    "    ('health','insurance'),\n",
    "    ('fox', 'news'),\n",
    "    ('bernie', 'sanders'),\n",
    "    ('hillary', 'clinton'),\n",
    "    ('barack', 'obama'),\n",
    "    ('donald', 'trump'),\n",
    "    ('joe', 'biden'),\n",
    "    ('joseph', 'biden'),\n",
    "    ('mass', 'shooting'),\n",
    "    ('mass', 'shootings'),\n",
    "    ('assault', 'weapon'),\n",
    "    ('assault', 'weapons'),\n",
    "    ('assault', 'weapons', 'ban'),\n",
    "    ('sergeant', 'at', 'arms'),\n",
    "    ('stop', 'and', 'frisk'),\n",
    "    ('medicare', 'for', 'all'),\n",
    "    ('public', 'option'),\n",
    "    ('beat', 'trump'),\n",
    "    ('articles', 'of', 'impeachment'),\n",
    "    ('new', 'york'),\n",
    "    ('hold', 'in', 'contempt'),\n",
    "    ('quid', 'pro', 'quo')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could do stemming, lemmatization, parts of speech, compound term extraction / named entity extraction, IF-IDF\n",
    "# lots of emoji's' now with nltk tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words, topic_names=None):\n",
    "    for ix, topic in enumerate(model.components_):\n",
    "        if not topic_names or not topic_names[ix]:\n",
    "            print(\"\\nTopic \", ix)\n",
    "        else:\n",
    "            print(\"\\nTopic: '\", topic_names[ix], \"'\")\n",
    "        print(\", \".join([feature_names[i]\n",
    "                         for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwe_tokenizer = MWETokenizer(multi_words)\n",
    "\n",
    "stop_words = ENGLISH_STOP_WORDS.union(additional_stop_words)\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    stop_words=stop_words,\n",
    "    tokenizer=lambda x: mwe_tokenizer.tokenize(word_tokenize(x)),\n",
    "    max_df=0.75\n",
    ")\n",
    "data_cv = cv.fit_transform(data_clean.text)\n",
    "data_dtm_raw = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm_raw.index = data_clean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>£</th>\n",
       "      <th>­</th>\n",
       "      <th>¯ツ¯</th>\n",
       "      <th>¿</th>\n",
       "      <th>¿philanthropist</th>\n",
       "      <th>élection</th>\n",
       "      <th>͜ʖ</th>\n",
       "      <th>͡ʘ</th>\n",
       "      <th>американец</th>\n",
       "      <th>говорить</th>\n",
       "      <th>как</th>\n",
       "      <th>–</th>\n",
       "      <th>—</th>\n",
       "      <th>—and</th>\n",
       "      <th>—donald</th>\n",
       "      <th>—gt</th>\n",
       "      <th>—gtevery</th>\n",
       "      <th>—the</th>\n",
       "      <th>—trump</th>\n",
       "      <th>—you</th>\n",
       "      <th>―</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   £  ­  ¯ツ¯  ¿  ¿philanthropist  élection  ͜ʖ  ͡ʘ  американец  говорить  как  \\\n",
       "0  0  0    0  0                0         0   0   0           0         0    0   \n",
       "1  0  0    0  0                1         0   0   0           0         0    0   \n",
       "3  0  0    0  0                0         0   0   0           0         0    0   \n",
       "4  0  0    0  0                0         0   0   0           0         0    0   \n",
       "6  0  0    0  0                0         0   0   0           0         0    0   \n",
       "\n",
       "   –  —  —and  —donald  —gt  —gtevery  —the  —trump  —you  ―  \n",
       "0  0  0     0        0    0         0     0       0     0  0  \n",
       "1  0  0     0        0    0         0     0       0     0  0  \n",
       "3  0  0     0        0    0         0     0       0     0  0  \n",
       "4  0  0     0        0    0         0     0       0     0  0  \n",
       "6  0  0     0        0    0         0     0       0     0  0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dtm_raw.iloc[:5, -171:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove russian words, emojis, other weird stuff\n",
    "data_dtm = data_dtm_raw.iloc[:, :-170]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dim Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance Ratio:  [0.08225951 0.04998326 0.03530142 0.03349842 0.02441368]\n",
      "\n",
      "Topic: ' Election '\n",
      "vote, bernie, biden, president, party, republicans, election, republican, democrats, candidate, better, warren, years, senate, support, house, sanders, money, democratic, country, voting, power, shit, voters, person, political, win, hillary, white, state\n",
      "\n",
      "Topic: ' Impeachment '\n",
      "power, congress, contempt, house, detain, court, senate, person, arrest, supreme, hold, law, impeachment, sergeant_at_arms, authority, republicans, vote, case, inherent, president, majority, dc, jail, impeached, persons, session, constitution, democrats, pursuant, longer\n",
      "\n",
      "Topic: ' Unclear - tax policy '\n",
      "bernie, biden, warren, sanders, congress, contempt, detain, candidate, power, arrest, supporters, court, vote, candidates, house, supreme, win, polls, person, sergeant_at_arms, voters, hillary, hold, authority, primary, inherent, pete, campaign, session, castro\n",
      "\n",
      "Topic: ' Unclear - maybe Health Care '\n",
      "healthcare, billion, tax, cost, pay, congress, taxes, health, detain, contempt, spending, bernie, costs, percent, money, insurance, power, biden, private, person, hospitals, care, warren, million, medicare, medical, arrest, services, paid, court\n",
      "\n",
      "Topic: ' Gun Violence/Assault Weapons ban '\n",
      "gun, vote, guns, ban, voting, laws, weapons, rights, rifles, used, away, amendment, person, firearms, common, detain, beto, number, voter, owners, firearm, mass_shootings, contempt, deaths, states, banning, state, control, assault_weapons, automatic\n"
     ]
    }
   ],
   "source": [
    "topic_names_lsa = ['Election', 'Impeachment', 'Unclear - tax policy',\n",
    "                   'Unclear - maybe Health Care', 'Gun Violence/Assault Weapons ban']\n",
    "\n",
    "lsa = TruncatedSVD(5)\n",
    "doc_topic_lsa = lsa.fit_transform(data_dtm)\n",
    "print('Explained Variance Ratio: ', lsa.explained_variance_ratio_)\n",
    "display_topics(\n",
    "    lsa,\n",
    "    cv.get_feature_names()[:-171],\n",
    "    30,\n",
    "    topic_names=topic_names_lsa\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Election</th>\n",
       "      <th>Impeachment</th>\n",
       "      <th>Unclear - tax policy</th>\n",
       "      <th>Unclear - maybe Health Care</th>\n",
       "      <th>Gun Violence/Assault Weapons ban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.22163</td>\n",
       "      <td>0.80219</td>\n",
       "      <td>-0.72862</td>\n",
       "      <td>-1.69740</td>\n",
       "      <td>0.79301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.22623</td>\n",
       "      <td>-0.30035</td>\n",
       "      <td>-3.15770</td>\n",
       "      <td>0.99486</td>\n",
       "      <td>-0.46923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.30386</td>\n",
       "      <td>-4.24771</td>\n",
       "      <td>4.54649</td>\n",
       "      <td>-0.44931</td>\n",
       "      <td>1.82468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.92904</td>\n",
       "      <td>-1.48703</td>\n",
       "      <td>-6.81543</td>\n",
       "      <td>-23.82862</td>\n",
       "      <td>9.03518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.58006</td>\n",
       "      <td>-6.09968</td>\n",
       "      <td>-1.32912</td>\n",
       "      <td>10.36532</td>\n",
       "      <td>0.29093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>14.90650</td>\n",
       "      <td>4.25741</td>\n",
       "      <td>-1.51642</td>\n",
       "      <td>-4.42267</td>\n",
       "      <td>-1.13338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>12.09701</td>\n",
       "      <td>4.63515</td>\n",
       "      <td>-2.50924</td>\n",
       "      <td>-2.45817</td>\n",
       "      <td>-1.09026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>6.02908</td>\n",
       "      <td>2.01382</td>\n",
       "      <td>-1.60848</td>\n",
       "      <td>-2.55960</td>\n",
       "      <td>-0.86775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>6.77289</td>\n",
       "      <td>-0.53095</td>\n",
       "      <td>-0.18075</td>\n",
       "      <td>-0.98894</td>\n",
       "      <td>0.24169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>6.95982</td>\n",
       "      <td>1.20536</td>\n",
       "      <td>-0.97632</td>\n",
       "      <td>-2.42692</td>\n",
       "      <td>-2.27367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>604 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Election  Impeachment  Unclear - tax policy  Unclear - maybe Health Care  \\\n",
       "0     5.22163      0.80219              -0.72862                     -1.69740   \n",
       "1     6.22623     -0.30035              -3.15770                      0.99486   \n",
       "2    11.30386     -4.24771               4.54649                     -0.44931   \n",
       "3    59.92904     -1.48703              -6.81543                    -23.82862   \n",
       "4    12.58006     -6.09968              -1.32912                     10.36532   \n",
       "..        ...          ...                   ...                          ...   \n",
       "599  14.90650      4.25741              -1.51642                     -4.42267   \n",
       "600  12.09701      4.63515              -2.50924                     -2.45817   \n",
       "601   6.02908      2.01382              -1.60848                     -2.55960   \n",
       "602   6.77289     -0.53095              -0.18075                     -0.98894   \n",
       "603   6.95982      1.20536              -0.97632                     -2.42692   \n",
       "\n",
       "     Gun Violence/Assault Weapons ban  \n",
       "0                             0.79301  \n",
       "1                            -0.46923  \n",
       "2                             1.82468  \n",
       "3                             9.03518  \n",
       "4                             0.29093  \n",
       "..                                ...  \n",
       "599                          -1.13338  \n",
       "600                          -1.09026  \n",
       "601                          -0.86775  \n",
       "602                           0.24169  \n",
       "603                          -2.27367  \n",
       "\n",
       "[604 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt = pd.DataFrame(doc_topic_lsa.round(5),\n",
    "                  #              index = example,\n",
    "                  columns=topic_names_lsa)\n",
    "Vt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwe_tokenizer = MWETokenizer(multi_words)\n",
    "\n",
    "stop_words = ENGLISH_STOP_WORDS.union(additional_stop_words)\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    stop_words=stop_words,\n",
    "    tokenizer=lambda x: mwe_tokenizer.tokenize(word_tokenize(x)),\n",
    "    #     max_df=0.75\n",
    ")\n",
    "data_cv = cv.fit_transform(data_clean.text)\n",
    "data_dtm_raw = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm_raw.index = data_clean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zum</th>\n",
       "      <th>£</th>\n",
       "      <th>­</th>\n",
       "      <th>¯ツ¯</th>\n",
       "      <th>¿</th>\n",
       "      <th>¿philanthropist</th>\n",
       "      <th>élection</th>\n",
       "      <th>͜ʖ</th>\n",
       "      <th>͡ʘ</th>\n",
       "      <th>американец</th>\n",
       "      <th>говорить</th>\n",
       "      <th>как</th>\n",
       "      <th>–</th>\n",
       "      <th>—</th>\n",
       "      <th>—and</th>\n",
       "      <th>—donald</th>\n",
       "      <th>—gt</th>\n",
       "      <th>—gtevery</th>\n",
       "      <th>—the</th>\n",
       "      <th>—trump</th>\n",
       "      <th>—you</th>\n",
       "      <th>―</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zum  £  ­  ¯ツ¯  ¿  ¿philanthropist  élection  ͜ʖ  ͡ʘ  американец  говорить  \\\n",
       "0    0  0  0    0  0                0         0   0   0           0         0   \n",
       "1    0  0  0    0  0                1         0   0   0           0         0   \n",
       "3    0  0  0    0  0                0         0   0   0           0         0   \n",
       "4    0  0  0    0  0                0         0   0   0           0         0   \n",
       "6    0  0  0    0  0                0         0   0   0           0         0   \n",
       "\n",
       "   как  –  —  —and  —donald  —gt  —gtevery  —the  —trump  —you  ―  \n",
       "0    0  0  0     0        0    0         0     0       0     0  0  \n",
       "1    0  0  0     0        0    0         0     0       0     0  0  \n",
       "3    0  0  0     0        0    0         0     0       0     0  0  \n",
       "4    0  0  0     0        0    0         0     0       0     0  0  \n",
       "6    0  0  0     0        0    0         0     0       0     0  0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dtm_raw.iloc[:5, -172:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove russian words, emojis, other weird stuff\n",
    "data_dtm = data_dtm_raw.iloc[:, :-171]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dim Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_topic_labels = [\n",
    "    'frustration at 2016 election',\n",
    "    'impeachment hearings',\n",
    "    'election (candidates)',\n",
    "    'healthcare',\n",
    "    'gun control',\n",
    "    'election (high level general terms)',\n",
    "    'yang',\n",
    "    'impeachment',\n",
    "    'right wing media',\n",
    "    'debate',\n",
    "    'bipartisanship????',\n",
    "    'midwest elections?????',\n",
    "    'identity',\n",
    "    'Bloomberg',\n",
    "    'biden/ukraine',\n",
    "    'economy; trump vs. Obama credit',\n",
    "    'election (states)',\n",
    "    'monetary policy',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic: ' frustration at 2016 election '\n",
      "trump, election, win, voted, hillary, won, vote, fuck, shit, trumps, voters, president, campaign, best, man, candidate, money, clinton, world, stupid\n",
      "\n",
      "Topic: ' impeachment hearings '\n",
      "congress, power, contempt, detain, house, court, person, arrest, supreme, senate, hold, sergeant_at_arms, authority, vote, law, inherent, case, dc, majority, persons\n",
      "\n",
      "Topic: ' election (candidates) '\n",
      "warren, sanders, bernie, biden, candidate, years, candidates, progressive, great, vote, far, goes, president, campaign, best, better, midwest, support, policy, literally\n",
      "\n",
      "Topic: ' healthcare '\n",
      "cost, healthcare, billion, pay, taxes, percent, spending, costs, health, hospitals, care, insurance, tax, private, medicare, million, medical, services, paid, trillion\n",
      "\n",
      "Topic: ' gun control '\n",
      "gun, guns, ban, weapons, laws, used, rifles, democrats, away, amendment, rights, number, control, common, use, stop, beto, firearms, government, owners\n",
      "\n",
      "Topic: ' election (high level general terms) '\n",
      "vote, voting, voter, state, election, states, votes, voters, party, rights, black, live, elections, win, government, laws, country, work, agree, voted\n",
      "\n",
      "Topic: ' yang '\n",
      "bloomberg, new_york, money, experience, mayor, warren, democratic, city, states, campaign, billionaire, running, fact, billionaires, effective, ads, win, candidate, years, stop_and_frisk\n",
      "\n",
      "Topic: ' impeachment '\n",
      "senate, impeachment, trump, president, impeached, republicans, trial, house, gop, office, democrats, election, criminal, pelosi, removed, crimes, process, impeach, evidence, mitch\n",
      "\n",
      "Topic: ' right wing media '\n",
      "bernie, biden, sanders, supporters, candidate, primary, voters, support, hillary, polls, win, election, vote, party, democratic, clinton, candidates, warren, voted, delegates\n",
      "\n",
      "Topic: ' debate '\n",
      "biden, castro, debate, bernie, candidates, candidate, question, trump, joe, harris, warren, better, tonight, yang, wrong, trying, healthcare, pete, far, school\n",
      "\n",
      "Topic: ' bipartisanship???? '\n",
      "republican, party, vote, republicans, left, democrats, trump, democrat, change, thought, democratic, better, political, try, thank, ill, friends, gop, voted, support\n",
      "\n",
      "Topic: ' midwest elections????? '\n",
      "trump, obama, president, economy, jobs, better, numbers, credit, job, recovery, million, created, blame, shit, literally, number, presidents, total, trade, clearly\n",
      "\n",
      "Topic: ' identity '\n",
      "white, privilege, black, women, man, pete, history, day, male, straight, use, men, life, far, masculinity, gay, guy, toxic, real, political\n",
      "\n",
      "Topic: ' Bloomberg '\n",
      "trump, tax, biden, returns, public, private, money, son, trumps, president, wrong, republicans, government, ukraine, question, taxes, care, evidence, joe, bidens\n",
      "\n",
      "Topic: ' biden/ukraine '\n",
      "yang, money, ubi, tax, government, work, pay, support, vat, wealth, better, policies, income, talk, policy, political, business, hour, climate, care\n",
      "\n",
      "Topic: ' economy; trump vs. Obama credit '\n",
      "obama, federal, national, border, ends, military, rescinds, funding, program, nuclear, revokes, billion, government, tax, use, states, war, children, veterans, oil\n",
      "\n",
      "Topic: ' election (states) '\n",
      "news, hillary, hate, years, fox, republicans, shit, fox_news, media, fact, cnn, act, country, work, party, left, having, cosponsored, wrong, working\n",
      "\n",
      "Topic: ' monetary policy '\n",
      "inflation, money, banks, assets, fed, cash, reserves, rates, prices, wage, economy, minimum, higher, bank, pay, rate, power, making, extra, rule\n"
     ]
    }
   ],
   "source": [
    "nmf_model = NMF(18, random_state=42)\n",
    "doc_topic_nmf = nmf_model.fit_transform(data_dtm)\n",
    "\n",
    "display_topics(\n",
    "    nmf_model,\n",
    "    cv.get_feature_names()[:-171],\n",
    "    20,\n",
    "    topic_names=nmf_topic_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_topic = pd.DataFrame(doc_topic_nmf.round(5),\n",
    "                          #              index = example,\n",
    "                          columns=nmf_topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frustration at 2016 election           0.230862\n",
       "impeachment                            0.222490\n",
       "election (states)                      0.205085\n",
       "right wing media                       0.198162\n",
       "bipartisanship????                     0.178529\n",
       "election (high level general terms)    0.166465\n",
       "debate                                 0.135731\n",
       "biden/ukraine                          0.116340\n",
       "identity                               0.107509\n",
       "midwest elections?????                 0.101219\n",
       "Bloomberg                              0.101086\n",
       "gun control                            0.096992\n",
       "yang                                   0.085711\n",
       "economy; trump vs. Obama credit        0.077292\n",
       "healthcare                             0.076765\n",
       "monetary policy                        0.066882\n",
       "election (candidates)                  0.065139\n",
       "impeachment hearings                   0.055271\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_topic.mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.lemmatize(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwe_tokenizer = MWETokenizer(multi_words)\n",
    "\n",
    "def complete_tokenizer(x):\n",
    "    return mwe_tokenizer.tokenize(word_tokenize(x))\n",
    "\n",
    "stop_words = ENGLISH_STOP_WORDS.union(additional_stop_words)\n",
    "\n",
    "cv = StemmedCountVectorizer(\n",
    "    stop_words=stop_words,\n",
    "    tokenizer=complete_tokenizer,\n",
    "    #     max_df=0.75\n",
    ")\n",
    "data_cv = cv.fit_transform(data_clean.text)\n",
    "data_dtm_raw = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm_raw.index = data_clean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zum</th>\n",
       "      <th>£</th>\n",
       "      <th>­</th>\n",
       "      <th>¯ツ¯</th>\n",
       "      <th>¿</th>\n",
       "      <th>¿philanthropist</th>\n",
       "      <th>élection</th>\n",
       "      <th>͜ʖ</th>\n",
       "      <th>͡ʘ</th>\n",
       "      <th>американец</th>\n",
       "      <th>говорить</th>\n",
       "      <th>как</th>\n",
       "      <th>–</th>\n",
       "      <th>—</th>\n",
       "      <th>—and</th>\n",
       "      <th>—donald</th>\n",
       "      <th>—gt</th>\n",
       "      <th>—gtevery</th>\n",
       "      <th>—the</th>\n",
       "      <th>—trump</th>\n",
       "      <th>—you</th>\n",
       "      <th>―</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zum  £  ­  ¯ツ¯  ¿  ¿philanthropist  élection  ͜ʖ  ͡ʘ  американец  говорить  \\\n",
       "0    0  0  0    0  0                0         0   0   0           0         0   \n",
       "1    0  0  0    0  0                1         0   0   0           0         0   \n",
       "3    0  0  0    0  0                0         0   0   0           0         0   \n",
       "4    0  0  0    0  0                0         0   0   0           0         0   \n",
       "6    0  0  0    0  0                0         0   0   0           0         0   \n",
       "\n",
       "   как  –  —  —and  —donald  —gt  —gtevery  —the  —trump  —you  ―  \n",
       "0    0  0  0     0        0    0         0     0       0     0  0  \n",
       "1    0  0  0     0        0    0         0     0       0     0  0  \n",
       "3    0  0  0     0        0    0         0     0       0     0  0  \n",
       "4    0  0  0     0        0    0         0     0       0     0  0  \n",
       "6    0  0  0     0        0    0         0     0       0     0  0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dtm_raw.iloc[:5, -172:-150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove russian words, emojis, other weird stuff\n",
    "data_dtm = data_dtm_raw.iloc[:, :-171]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_topic_labels = [\n",
    "    '2016_election_frustration',\n",
    "    'impeachment_proceedings',\n",
    "    'healthcare',\n",
    "    'primary_candidates',\n",
    "    'gun_control',\n",
    "    'election_general_terms',\n",
    "    'right_wing_media',\n",
    "    'impeachment',\n",
    "    'yang_ubi',\n",
    "    'primary_debates',\n",
    "    'bloomberg',\n",
    "    'econ_trump_vs_obama',\n",
    "    'race_identity',\n",
    "    'tax_return_ukraine_biden',\n",
    "    'election_midwest_swing',\n",
    "    'monetary_policy',\n",
    "    'rep_dem_comparison',\n",
    "    'miltary_and_immigration'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic: ' 2016_election_frustration '\n",
      "trump, voted, win, fuck, supporter, election, hillary, vote, shit, lie, republican, war, believe, president, world, money, stupid, won, year, better\n",
      "\n",
      "Topic: ' impeachment_proceedings '\n",
      "power, congress, contempt, person, detain, court, house, arrest, supreme, senate, law, hold, sergeant_at_arms, authority, vote, jail, inherent, case, majority, dc\n",
      "\n",
      "Topic: ' healthcare '\n",
      "cost, tax, billion, healthcare, hospital, pay, rate, percent, spending, health, insurance, service, care, increase, medicare, million, medical, saving, private, paid\n",
      "\n",
      "Topic: ' primary_candidates '\n",
      "bernie, warren, sander, candidate, biden, supporter, vote, support, primary, progressive, poll, year, win, democratic, delegate, voter, hillary, campaign, literally, obama\n",
      "\n",
      "Topic: ' gun_control '\n",
      "gun, ban, law, weapon, rifle, firearm, democrat, death, used, mean, amendment, away, number, owner, right, control, common, use, stop, beto\n",
      "\n",
      "Topic: ' election_general_terms '\n",
      "vote, voting, voter, state, election, party, candidate, voted, win, black, democrat, government, right, democratic, country, ballot, responsibility, work, reason, live\n",
      "\n",
      "Topic: ' right_wing_media '\n",
      "hillary, bernie, year, hate, news, fact, fox, medium, shit, fox_news, clinton, cnn, act, lie, woman, support, cosponsored, link, work, democratic\n",
      "\n",
      "Topic: ' impeachment '\n",
      "senate, impeachment, trump, president, impeached, trial, republican, office, house, gop, crime, election, democrat, criminal, pelosi, vote, removed, power, mean, process\n",
      "\n",
      "Topic: ' yang_ubi '\n",
      "yang, ubi, policy, money, work, government, tax, pay, job, support, candidate, talk, better, year, vat, country, business, income, hour, care\n",
      "\n",
      "Topic: ' primary_debates '\n",
      "biden, candidate, debate, bernie, castro, question, trump, joe, harris, supporter, talk, answer, wrong, tonight, kid, pete, better, trying, yang, healthcare\n",
      "\n",
      "Topic: ' bloomberg '\n",
      "bloomberg, billionaire, money, new_york, experience, warren, city, mayor, candidate, democratic, campaign, fact, ad, running, policy, state, year, effective, stop_and_frisk, win\n",
      "\n",
      "Topic: ' econ_trump_vs_obama '\n",
      "president, job, trump, obama, economy, number, million, better, work, credit, lie, recovery, created, shit, fact, blame, promise, literally, total, trade\n",
      "\n",
      "Topic: ' race_identity '\n",
      "white, privilege, black, woman, man, day, male, history, mean, party, life, pete, men, straight, use, racist, post, problem, believe, gay\n",
      "\n",
      "Topic: ' tax_return_ukraine_biden '\n",
      "tax, return, public, private, money, republican, son, biden, year, citizen, government, business, president, wrong, politician, question, investigation, wealth, ukraine, care\n",
      "\n",
      "Topic: ' election_midwest_swing '\n",
      "state, poll, voter, election, win, mean, clinton, campaign, result, white, michigan, polling, swing, chance, far, winning, democrat, biden, primary, data\n",
      "\n",
      "Topic: ' monetary_policy '\n",
      "bank, inflation, money, asset, fed, rate, reserve, price, cash, wage, economy, minimum, higher, investment, pay, buy, mean, extra, rule, power\n",
      "\n",
      "Topic: ' rep_dem_comparison '\n",
      "republican, party, democrat, left, vote, gop, racist, thought, better, change, political, conservative, try, support, friend, belief, hate, democratic, ill, thank\n",
      "\n",
      "Topic: ' miltary_and_immigration '\n",
      "obama, military, federal, end, national, border, state, rule, rescinds, veteran, funding, year, program, war, nuclear, government, protection, reason, child, billion\n"
     ]
    }
   ],
   "source": [
    "nmf_model = NMF(18, random_state=42, alpha=0)\n",
    "doc_topic_nmf = nmf_model.fit_transform(data_dtm)\n",
    "\n",
    "display_topics(\n",
    "    nmf_model,\n",
    "    cv.get_feature_names(),\n",
    "    20,\n",
    "    topic_names=nmf_topic_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Winning Topic Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../data/interim/rDemocrats_nmf.pickle', 'wb') as write_file:\n",
    "    pickle.dump(nmf_model, write_file)\n",
    "    \n",
    "with open('../../data/interim/rDemocrats_CV.pickle', 'wb') as write_file:\n",
    "    pickle.dump(cv, write_file)\n",
    "    \n",
    "with open('../../data/interim/rDemocrats_doc_topic.pickle', 'wb') as write_file:\n",
    "    pickle.dump(pd.DataFrame(doc_topic_nmf, columns=nmf_topic_labels), write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "class StemmedCountVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.lemmatize(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwe_tokenizer = MWETokenizer(multi_words)\n",
    "\n",
    "stop_words = ENGLISH_STOP_WORDS.union(additional_stop_words)\n",
    "\n",
    "cv = StemmedCountVectorizer(\n",
    "    stop_words=stop_words,\n",
    "    tokenizer=lambda x: mwe_tokenizer.tokenize(word_tokenize(x)),\n",
    "    #     max_df=0.75\n",
    ")\n",
    "data_cv = cv.fit_transform(data_clean.text)\n",
    "data_dtm_raw = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm_raw.index = data_clean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic  0\n",
      "trump, republican, voted, hillary, election, win, supporter, president, fuck, vote, shit, lie, year, democrat, biden, won, money, stupid, matter, war\n",
      "\n",
      "Topic  1\n",
      "power, congress, contempt, person, detain, court, house, arrest, supreme, senate, law, hold, sergeant_at_arms, authority, vote, jail, inherent, case, majority, dc\n",
      "\n",
      "Topic  2\n",
      "cost, tax, billion, healthcare, hospital, pay, rate, percent, spending, health, insurance, service, care, increase, medicare, million, medical, private, saving, paid\n",
      "\n",
      "Topic  3\n",
      "bernie, warren, sander, candidate, biden, supporter, support, vote, primary, hillary, progressive, year, poll, win, democratic, voter, clinton, delegate, literally, obama\n",
      "\n",
      "Topic  4\n",
      "gun, ban, law, weapon, rifle, firearm, democrat, death, used, mean, amendment, away, number, owner, right, use, control, stop, common, beto\n",
      "\n",
      "Topic  5\n",
      "vote, voting, voter, election, state, party, candidate, black, voted, win, right, country, responsibility, democratic, ballot, government, reason, work, democrat, live\n",
      "\n",
      "Topic  6\n",
      "republican, party, democrat, left, racist, gop, change, political, thought, better, vote, support, conservative, trump, try, friend, democratic, belief, hate, country\n",
      "\n",
      "Topic  7\n",
      "senate, impeachment, trump, president, impeached, republican, trial, office, house, gop, crime, election, democrat, criminal, pelosi, removed, power, vote, mean, evidence\n",
      "\n",
      "Topic  8\n",
      "state, poll, voter, election, mean, win, white, campaign, result, michigan, far, clinton, polling, swing, chance, democrat, winning, popular, data, woman\n",
      "\n",
      "Topic  9\n",
      "biden, candidate, debate, bernie, castro, question, trump, joe, harris, yang, talk, answer, better, wrong, supporter, pete, tonight, kid, trying, healthcare\n",
      "\n",
      "Topic  10\n",
      "bloomberg, money, warren, billionaire, candidate, new_york, experience, city, mayor, campaign, democratic, policy, ad, fact, running, president, year, state, far, effective\n",
      "\n",
      "Topic  11\n",
      "president, job, obama, economy, trump, number, work, better, million, credit, recovery, created, shit, blame, lie, promise, literally, cut, fact, trade\n",
      "\n",
      "Topic  12\n",
      "tax, money, yang, government, pay, year, business, wealth, return, work, ubi, policy, bank, income, american, public, price, care, vat, inflation\n",
      "\n",
      "Topic  13\n",
      "woman, white, year, news, hillary, fox, fact, shit, hate, medium, fox_news, work, day, support, country, lie, reason, life, cnn, bernie\n"
     ]
    }
   ],
   "source": [
    "nmf_model = NMF(14, random_state=42, alpha=0)\n",
    "doc_topic_nmf = nmf_model.fit_transform(data_dtm)\n",
    "\n",
    "display_topics(\n",
    "    nmf_model,\n",
    "    cv.get_feature_names()[:-171],\n",
    "    20,\n",
    "#     topic_names=nmf_topic_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data_raw.copy()\n",
    "data_clean.text = data_clean.text.map(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.lemmatize(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mwe_tokenizer = MWETokenizer(multi_words)\n",
    "\n",
    "stop_words = ENGLISH_STOP_WORDS.union(additional_stop_words)\n",
    "\n",
    "cv = StemmedCountVectorizer(\n",
    "    stop_words=stop_words,\n",
    "    tokenizer=lambda x: mwe_tokenizer.tokenize(word_tokenize(x)),\n",
    "    #     max_df=0.75\n",
    ")\n",
    "data_cv = cv.fit_transform(data_clean.text)\n",
    "data_dtm_raw = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "data_dtm_raw.index = data_clean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zum</th>\n",
       "      <th>£</th>\n",
       "      <th>­</th>\n",
       "      <th>¯ツ¯</th>\n",
       "      <th>¿</th>\n",
       "      <th>¿philanthropist</th>\n",
       "      <th>élection</th>\n",
       "      <th>͜ʖ</th>\n",
       "      <th>͡ʘ</th>\n",
       "      <th>американец</th>\n",
       "      <th>говорить</th>\n",
       "      <th>как</th>\n",
       "      <th>–</th>\n",
       "      <th>—</th>\n",
       "      <th>—and</th>\n",
       "      <th>—donald</th>\n",
       "      <th>—gt</th>\n",
       "      <th>—gtevery</th>\n",
       "      <th>—the</th>\n",
       "      <th>—trump</th>\n",
       "      <th>—you</th>\n",
       "      <th>―</th>\n",
       "      <th>”</th>\n",
       "      <th>„</th>\n",
       "      <th>•</th>\n",
       "      <th>…</th>\n",
       "      <th>‪can</th>\n",
       "      <th>⁉️</th>\n",
       "      <th>€</th>\n",
       "      <th>≠</th>\n",
       "      <th>☺</th>\n",
       "      <th>✊</th>\n",
       "      <th>❄️</th>\n",
       "      <th>❌❌❌</th>\n",
       "      <th>❤</th>\n",
       "      <th>❤️</th>\n",
       "      <th>❤️❤️</th>\n",
       "      <th>⢀⣠⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⣠⣤⣶⣶</th>\n",
       "      <th>⣿⣿⣿⣿⣿⡏⠉⠛⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⣿</th>\n",
       "      <th>⣿⣿⣿⣿⣿⣿⠀⠀⠀⠈⠛⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠿⠛⠉⠁⠀⣿</th>\n",
       "      <th>⣿⣿⣿⣿⣿⣿⣧⡀⠀⠀⠀⠀⠙⠿⠿⠿⠻⠿⠿⠟⠿⠛⠉⠀⠀⠀⠀⠀⣸⣿</th>\n",
       "      <th>⣿⣿⣿⣿⣿⣿⣿⣷⣄⠀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⣿⣿</th>\n",
       "      <th>⣿⣿⣿⣿⣿⣿⣿⣿⠃⠀⠀⠈⠉⠀⠀⠤⠄⠀⠀⠀⠉⠁⠀⠀⠀⠀⢿⣿⣿⣿</th>\n",
       "      <th>⣿⣿⣿⣿⣿⣿⣿⣿⡀⠉⠀⠀⠀⠀⠀⢄⠀⢀⠀⠀⠀⠀⠉⠉⠁⠀⠀⣿⣿⣿</th>\n",
       "      <th>⣿⣿⣿⣿⣿⣿⣿⣿⡟⠀⠀⢰⣹⡆⠀⠀⠀⠀⠀⠀⣭⣷⠀⠀⠀⠸⣿⣿⣿⣿</th>\n",
       "      <th>⣿⣿⣿⣿⣿⣿⣿⣿⢾⣿⣷⠀⠀⠀⠀⡠⠤⢄⠀⠀⠀⠠⣿⣿⣷⠀⢸⣿⣿⣿</th>\n",
       "      <th>⣿⣿⣿⣿⣿⣿⣿⣿⣧⠀⠀⠀⠀⠀⠀⠀⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢹⣿⣿</th>\n",
       "      <th>⣿⣿⣿⣿⣿⣿⣿⣿⣿⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿</th>\n",
       "      <th>⣿⣿⣿⣿⣿⣿⣿⣿⣿⠏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠠⣴⣿⣿⣿⣿</th>\n",
       "      <th>⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠀⠀⠀⢰⣿⣿⣿⣿</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zum  £  ­  ¯ツ¯  ¿  ¿philanthropist  élection  ͜ʖ  ͡ʘ  американец  говорить  \\\n",
       "0    0  0  0    0  0                0         0   0   0           0         0   \n",
       "1    0  0  0    0  0                1         0   0   0           0         0   \n",
       "3    0  0  0    0  0                0         0   0   0           0         0   \n",
       "4    0  0  0    0  0                0         0   0   0           0         0   \n",
       "6    0  0  0    0  0                0         0   0   0           0         0   \n",
       "\n",
       "   как  –  —  —and  —donald  —gt  —gtevery  —the  —trump  —you  ―  ”  „  •  …  \\\n",
       "0    0  0  0     0        0    0         0     0       0     0  0  2  0  0  0   \n",
       "1    0  0  0     0        0    0         0     0       0     0  0  2  0  0  0   \n",
       "3    0  0  0     0        0    0         0     0       0     0  0  1  0  0  0   \n",
       "4    0  0  0     0        0    0         0     0       0     0  0  1  0  0  0   \n",
       "6    0  0  0     0        0    0         0     0       0     0  0  3  0  0  0   \n",
       "\n",
       "   ‪can  ⁉️  €  ≠  ☺  ✊  ❄️  ❌❌❌  ❤  ❤️  ❤️❤️  ⢀⣠⣾⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠀⠀⠀⠀⣠⣤⣶⣶  \\\n",
       "0     0   0  0  0  0  0   0    0  0   0     0                               0   \n",
       "1     0   0  0  0  0  0   0    0  0   0     0                               0   \n",
       "3     0   0  0  0  0  0   0    0  0   0     0                               0   \n",
       "4     0   0  0  0  0  0   0    0  0   0     0                               0   \n",
       "6     0   0  0  0  0  0   0    0  0   0     0                               0   \n",
       "\n",
       "   ⣿⣿⣿⣿⣿⡏⠉⠛⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⣿  ⣿⣿⣿⣿⣿⣿⠀⠀⠀⠈⠛⢿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠿⠛⠉⠁⠀⣿  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "6                               0                               0   \n",
       "\n",
       "   ⣿⣿⣿⣿⣿⣿⣧⡀⠀⠀⠀⠀⠙⠿⠿⠿⠻⠿⠿⠟⠿⠛⠉⠀⠀⠀⠀⠀⣸⣿  ⣿⣿⣿⣿⣿⣿⣿⣷⣄⠀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⣿⣿  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "6                               0                               0   \n",
       "\n",
       "   ⣿⣿⣿⣿⣿⣿⣿⣿⠃⠀⠀⠈⠉⠀⠀⠤⠄⠀⠀⠀⠉⠁⠀⠀⠀⠀⢿⣿⣿⣿  ⣿⣿⣿⣿⣿⣿⣿⣿⡀⠉⠀⠀⠀⠀⠀⢄⠀⢀⠀⠀⠀⠀⠉⠉⠁⠀⠀⣿⣿⣿  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "6                               0                               0   \n",
       "\n",
       "   ⣿⣿⣿⣿⣿⣿⣿⣿⡟⠀⠀⢰⣹⡆⠀⠀⠀⠀⠀⠀⣭⣷⠀⠀⠀⠸⣿⣿⣿⣿  ⣿⣿⣿⣿⣿⣿⣿⣿⢾⣿⣷⠀⠀⠀⠀⡠⠤⢄⠀⠀⠀⠠⣿⣿⣷⠀⢸⣿⣿⣿  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "6                               0                               0   \n",
       "\n",
       "   ⣿⣿⣿⣿⣿⣿⣿⣿⣧⠀⠀⠀⠀⠀⠀⠀⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢹⣿⣿  ⣿⣿⣿⣿⣿⣿⣿⣿⣿⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿  \\\n",
       "0                               0                               0   \n",
       "1                               0                               0   \n",
       "3                               0                               0   \n",
       "4                               0                               0   \n",
       "6                               0                               0   \n",
       "\n",
       "   ⣿⣿⣿⣿⣿⣿⣿⣿⣿⠏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠠⣴⣿⣿⣿⣿  ⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠀⠀⠀⢰⣿⣿⣿⣿  \n",
       "0                               0                               0  \n",
       "1                               0                               0  \n",
       "3                               0                               0  \n",
       "4                               0                               0  \n",
       "6                               0                               0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dtm_raw.iloc[:5, -172:-122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove russian words, emojis, other weird stuff\n",
    "data_dtm = data_dtm_raw.iloc[:, :-171]\n",
    "data_cv = data_cv[:, :-171]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dim Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word = data_cv.transpose()\n",
    "# haven't removed the russian and stuff\n",
    "corpus = matutils.Sparse2Corpus(doc_word)\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-3b41dc00edd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    978\u001b[0m                         \u001b[0mpass_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_no\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m                     )\n\u001b[0;32m--> 980\u001b[0;31m                     \u001b[0mgammat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_estep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_alpha\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36mdo_estep\u001b[0;34m(self, chunk, state)\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msstats\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumdocs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# avoids calling len(chunk) on a generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/metis/lib/python3.7/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;31m# Substituting the value of the optimal phi back into\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;31m# the update for gamma gives this update. Cf. Lee&Seung 2001.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m                 \u001b[0mgammad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcts\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mphinorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpElogbetad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m                 \u001b[0mElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgammad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                 \u001b[0mexpElogthetad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mElogthetad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, num_topics=18, id2word=id2word, passes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.print_topics(num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
